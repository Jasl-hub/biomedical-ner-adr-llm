# -*- coding: utf-8 -*-
"""NLP_Assignment.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1dujhvR1N73wYyPy2G889ZDRcEMNSaSeJ
"""

from google.colab import drive
drive.mount('/content/drive')

!unzip '/content/drive/MyDrive/CADEC.v2.zip' -d '/content/CADECdataset'

"""Step 1: Enumerate distinct entities of each label type"""

import os

sub_dir = "/content/CADECdataset/cadec/original"

all_files = [f for f in os.listdir(sub_dir) if os.path.isfile(os.path.join(sub_dir, f))]

# Confirm this prints 1250+ .txt files
print("Sample files in original/:", os.listdir(sub_dir)[:5])
print(len(all_files))

#for one file of the subdirectory chosen above
sample_file = os.path.join(sub_dir, os.listdir(sub_dir)[3])
print(sample_file)

with open(sample_file, 'r', encoding='utf-8') as file:
    for line in file:
        print("Line:", line)

#for 1250 files
# Loop through each file
for file_name in all_files:
    file_path = os.path.join(sub_dir, file_name)

    # Open and read file line by line
    with open(file_path, 'r', encoding='utf-8') as file:
        print(f"\n--- Contents of {file_name} ---")
        for line in file:
            print("Line:", line.strip())  # strip() removes extra newline

#giving distinct entities i.e. ADR, drug, disease, symptom for each label type
import os
from collections import defaultdict

entity_types = ['ADR', 'Drug', 'Disease', 'Symptom']

# Dictionary to hold unique entities per label
entities_by_type = defaultdict(set)

# Get all .ann files
ann_files = [f for f in os.listdir(sub_dir) if f.endswith(('.ann','.txt'))]

for file_name in ann_files:
    file_path = os.path.join(sub_dir, file_name)
    with open(file_path, 'r', encoding='utf-8') as f:
        for line in f:
            if line.startswith('T'):
                parts = line.strip().split('\t')
                if len(parts) < 3:
                    continue
                entity_info = parts[1]
                entity_text = parts[2].strip()

                label = entity_info.split()[0]
                if label in entity_types:
                    entities_by_type[label].add(entity_text)

# Print results
for label in entity_types:
    entities = sorted(entities_by_type[label])
    print(f"\n{label} Entities (Total: {len(entities)}):")
    for ent in entities:
        print(f"- {ent}")

import os
import json
import csv
from collections import defaultdict

sub_dir = "/content/CADECdataset/cadec/original"
entity_types = ['ADR', 'Drug', 'Disease', 'Symptom']

global_entities_by_type = defaultdict(set)
entities_by_file = defaultdict(lambda: defaultdict(set))

# Get all .ann files
ann_files = [f for f in os.listdir(sub_dir) if f.endswith('.ann')]

for file_name in ann_files:
    file_path = os.path.join(sub_dir, file_name)
    with open(file_path, 'r', encoding='utf-8') as f:
        for line in f:
            if line.startswith('T'):
                parts = line.strip().split('\t')
                if len(parts) < 3:
                    continue
                entity_info = parts[1]
                entity_text = parts[2].strip()

                label = entity_info.split()[0]
                if label in entity_types:
                    global_entities_by_type[label].add(entity_text)
                    entities_by_file[file_name][label].add(entity_text)

# --- ✅ 1. Save per file entity listing to JSON ---
output_file_json = "entities_by_file.json"
# Convert sets to lists for JSON
entities_by_file_json = {
    file: {label: list(ents) for label, ents in labels.items()}
    for file, labels in entities_by_file.items()
}
with open(output_file_json, 'w', encoding='utf-8') as f_json:
    json.dump(entities_by_file_json, f_json, indent=4, ensure_ascii=False)
print(f"✅ Saved per-file entity list to: {output_file_json}")

# --- ✅ 2. Save global summary to CSV ---
output_file_csv = "global_entity_summary.csv"
with open(output_file_csv, 'w', encoding='utf-8', newline='') as f_csv:
    writer = csv.writer(f_csv)
    writer.writerow(['Label', 'Entity'])

    for label in entity_types:
        for entity in sorted(global_entities_by_type[label]):
            writer.writerow([label, entity])
print(f"✅ Saved global entity summary to: {output_file_csv}")

# import shutil

# shutil.rmtree("/content/entities_by_file.json", ignore_errors=True)
# shutil.rmtree("/content/global_entity_summary.csv", ignore_errors=True)

"""Step 2: Use HuggingFace LLM for IOB Labelling

*Prompt-Based Sequence Labelling using a Suitable LLM*


Objective:

1. Use a suitable LLM to label each word in a patient forum post ('text') using BIO/IOB format

2. Convert that BIO labelling into the CADEC annotation format (like in original/ subdirectory)
"""

!pip install torchinfo
#for model summary

from transformers import AutoTokenizer, AutoModelForTokenClassification, pipeline
from torchinfo import summary
import torch

# Load model and tokenizer
model_name = "d4data/biomedical-ner-all"
model = AutoModelForTokenClassification.from_pretrained(model_name)
tokenizer = AutoTokenizer.from_pretrained(model_name)


ner_pipeline = pipeline("ner", model=model, tokenizer=tokenizer, aggregation_strategy="simple")

###for_Self_learning
from transformers import AutoTokenizer, AutoModelForTokenClassification
from torchinfo import summary
import torch

# Load model and tokenizer
model_name = "d4data/biomedical-ner-all"
model = AutoModelForTokenClassification.from_pretrained(model_name)
tokenizer = AutoTokenizer.from_pretrained(model_name)

# Tokenize sample input
inputs = tokenizer("Aspirin was prescribed for pain", return_tensors="pt")

# Send model to eval and device (optional)
model.eval()

# Use torchinfo with proper kwargs unpacking
summary(model, input_data=dict(inputs))

###for_Self_learning
print(model)
print("--------------------------------------------------------------------------------")
print("first layer :", model.distilbert.transformer.layer[0])  # First layer

print("--------------------------------------------------------------------------------")
# Total number of parameters
print(f"Total parameters: {model.num_parameters():,}")

print("--------------------------------------------------------------------------------")
print(model.classifier)

print("--------------------------------------------------------------------------------")
#To inspect 84 class labels of this model
from transformers import AutoConfig

model_name = "d4data/biomedical-ner-all"
config = AutoConfig.from_pretrained(model_name)

# Print label mapping
print(config.id2label)

# Paths
text_dir = "/content/CADECdataset/cadec/text"
output_bio_dir = "/content/output_bio"
output_cadec_dir = "/content/output_cadec"

# Create output folders
os.makedirs(output_bio_dir, exist_ok=True)
os.makedirs(output_cadec_dir, exist_ok=True)

import shutil

# shutil.rmtree("/content/output_bio", ignore_errors=True)
# shutil.rmtree("/content/output_cadec", ignore_errors=True)

def convert_to_bio(text, ner_results):
    encoding = tokenizer(text, return_offsets_mapping=True, return_tensors="pt", truncation=True)
    tokens = tokenizer.convert_ids_to_tokens(encoding["input_ids"][0])
    offsets = encoding["offset_mapping"][0].tolist()

    bio_tags = ["O"] * len(tokens)

    for ent in ner_results:
        start, end, label = ent["start"], ent["end"], ent["entity_group"].upper()
        first = True
        for i, (tok, (s, e)) in enumerate(zip(tokens, offsets)):
            if s == e:  # Skip special tokens like [CLS], [SEP]
                continue
            if s >= start and e <= end:
                bio_tags[i] = f"B-{label}" if first else f"I-{label}"
                first = False

    # Merge subwords and apply same tag to full word
    merged = []
    current_word = ""
    current_tag = "O"
    for tok, tag in zip(tokens, bio_tags):
        if tok.startswith("##"):
            current_word += tok[2:]
        else:
            if current_word:
                merged.append((current_word, current_tag))
            current_word = tok
            current_tag = tag
    if current_word:
        merged.append((current_word, current_tag))

    return merged

# # --- Helper: Convert to BIO Format ---
# def convert_to_bio(text, ner_results):
#     tokens = tokenizer.tokenize(text)
#     token_offsets = []
#     current = 0
#     for token in tokens:
#         cleaned = token.replace("##", "")
#         start = text.find(cleaned, current)
#         end = start + len(cleaned)
#         token_offsets.append((token, start, end))
#         current = end

#     bio_tags = ["O"] * len(tokens)
#     for entity in ner_results:
#         ent_start = entity["start"]
#         ent_end = entity["end"]
#         ent_label = entity["entity_group"].upper()
#         for i, (tok, tok_start, tok_end) in enumerate(token_offsets):
#             if tok_start >= ent_start and tok_end <= ent_end:
#                 tag = "B-" + ent_label if tok_start == ent_start else "I-" + ent_label
#                 bio_tags[i] = tag

#     return list(zip(tokens, bio_tags))

# --- Process Each File ---
for fname in os.listdir(text_dir):
    if fname.endswith(".txt"):
        file_path = os.path.join(text_dir, fname)
        with open(file_path, "r", encoding="utf-8") as f:
            text = f.read()

        bio_result = convert_to_bio(text, ner_pipeline(text))

        # Save BIO-tagged output
        out_path = os.path.join(output_bio_dir, fname.replace(".txt", "_bio.txt"))
        with open(out_path, "w", encoding="utf-8") as out_file:
            for token, tag in bio_result:
                out_file.write(f"{token}\t{tag}\n")

        print(f"✅ BIO tags written for {fname}")

# text = "I took Lipitor and had muscle pain and headaches after 3 days."

# results = ner_pipeline(text)

# for entity in results:
#     print(f"{entity['word']} → Model Output/Predicted Label: {entity['entity_group']}, confidence score:({entity['score']:.2f})")

"""2b. Convert BIO to CADEC format:

that is : `<ID> <LABEL> <START_CHAR> <END_CHAR>	<ENTITY_TEXT>`

"""

import shutil
shutil.rmtree("/content/output_cadec", ignore_errors=True)

import os

output_cadec_dir = "/content/output_cadec"
os.makedirs(output_cadec_dir, exist_ok=True)

# --- Load original text file ---
def load_text(filepath):
    with open(filepath, "r", encoding="utf-8") as f:
        return f.read()

def merge_tokens_bio_to_spans(tokens, tags, text, filename):
    spans = []
    entity_id = 1
    i = 0
    cursor = 0  # Start search after last match to avoid duplicates

    while i < len(tokens):
        tag = tags[i]
        if tag.startswith("B-"):
            label = tag[2:]
            span_tokens = [tokens[i]]
            i += 1
            while i < len(tokens) and tags[i] == f"I-{label}":
                span_tokens.append(tokens[i])
                i += 1

            # Merge subwords: '##ing' should become 'ing'
            span_text = ""
            for idx, tok in enumerate(span_tokens):
                if tok.startswith("##"):
                    span_text += tok[2:]
                elif idx > 0 and not span_tokens[idx-1].endswith("##"):
                    span_text += " " + tok
                else:
                    span_text += tok

            # Remove unnecessary ## if any remain
            span_text = span_text.replace(" ##", "").replace("##", "")

            # Skip short or noisy tokens/entities
            if len(span_text) < 2 or span_text.lower() in {"bp", "98", "/", "'"}:
                print(f"⚠️ Skipping short or noisy token: '{span_text}'")
                continue

            # Try to find the entity in the original text
            start = text.find(span_text, cursor)

            if start == -1:
              # Retry with lowercase fallback
              fallback_index = text.lower().find(span_text.lower(), cursor)
              if fallback_index != -1:
                  start = fallback_index
                  end = start + len(span_text)
                  spans.append((f"T{entity_id}", label, start, end, text[start:end]))
                  print(f"🔁 [{filename}] Fallback matched '{span_text}' at {start}")
                  cursor = end
                  entity_id += 1
                  continue
              else:
                  print(f"⚠️ [{filename}] Could not find span: '{span_text}'")
                  continue
            else:
              end = start + len(span_text)
              spans.append((f"T{entity_id}", label, start, end, text[start:end]))
              print(f"[{filename}] Token: '{span_text}' | Text Snippet: '{text[start-5:start+10]}'")
              cursor = end
              entity_id += 1


        else:
            i += 1

    print(f"✅ Found {len(spans)} spans")
    return spans

# --- Process BIO files and create .ann ---
count = 0
for filename in sorted(os.listdir(output_bio_dir)):
    if not filename.endswith("_bio.txt"):
        continue

    base_name = filename.replace("_bio.txt", "")
    text_path = os.path.join(text_dir, base_name + ".txt")
    bio_path = os.path.join(output_bio_dir, filename)

    if not os.path.exists(text_path):
        print(f"❌ Missing original text for: {base_name}.txt")
        continue

    text = load_text(text_path)

    # Load BIO-tagged tokens
    tokens, tags = [], []
    with open(bio_path, "r", encoding="utf-8") as f:
        for line in f:
            if line.strip():
                token, tag = line.strip().split("\t")
                tokens.append(token)
                tags.append(tag)

    # Convert to spans
    spans = merge_tokens_bio_to_spans(tokens, tags, text, filename)

    # Write to CADEC-style .ann
    ann_path = os.path.join(output_cadec_dir, base_name + ".ann")
    with open(ann_path, "w", encoding="utf-8") as f:
        for tid, label, start, end, span_text in spans:
            f.write(f"{tid}\t{label} {start} {end}\t{span_text}\n")

    count += 1
    if count % 100 == 0:
        print(f"✅ Processed {count} CADEC files")

print(f"\n🎉 Finished generating {count} CADEC-format .ann files from BIO outputs.")

# def load_text(filepath):
#     with open(filepath, "r", encoding="utf-8") as f:
#         return f.read()

# def merge_tokens_bio_to_spans(tokens, tags, text):
#     spans = []
#     i = 0
#     entity_id = 1
#     char_idx = 0  # pointer for original text

#     while i < len(tokens):
#         tag = tags[i]
#         if tag.startswith("B-"):
#             label = tag[2:]
#             start_token = tokens[i].replace("##", "")
#             start_pos = text.find(start_token, char_idx)
#             if start_pos == -1:
#                 i += 1
#                 continue
#             end_pos = start_pos + len(start_token)
#             span_text = start_token
#             char_idx = end_pos
#             i += 1

#             # Collect subsequent I- tokens
#             while i < len(tokens) and tags[i] == "I-" + label:
#                 token = tokens[i].replace("##", "")
#                 next_pos = text.find(token, char_idx)
#                 if next_pos == -1:
#                     break
#                 span_text += text[char_idx:next_pos] + token
#                 end_pos = next_pos + len(token)
#                 char_idx = end_pos
#                 i += 1

#             spans.append((f"T{entity_id}", label, start_pos, end_pos, span_text.strip()))
#             entity_id += 1
#         else:
#             token = tokens[i].replace("##", "")
#             char_idx = text.find(token, char_idx)
#             if char_idx != -1:
#                 char_idx += len(token)
#             i += 1
#     return spans

# # Process all .bio.txt files
# count = 0
# for filename in sorted(os.listdir(output_bio)):
#     if not filename.endswith("_bio.txt"):
#         continue

#     base_name = filename.replace("_bio.txt", "")
#     text_path = os.path.join(text_dir, base_name + ".txt")
#     bio_path = os.path.join(output_bio, filename)

#     if not os.path.exists(text_path):
#         continue

#     text = load_text(text_path)

#     # Load tokens and tags
#     tokens = []
#     tags = []
#     with open(bio_path, "r", encoding="utf-8") as f:
#         for line in f:
#             if line.strip():
#                 token, tag = line.strip().split("\t")
#                 tokens.append(token)
#                 tags.append(tag)

#     # Convert to spans
#     spans = merge_tokens_bio_to_spans(tokens, tags, text)

#     # Save to CADEC .ann format
#     ann_path = os.path.join(output_cadec_dir, base_name + ".ann")
#     with open(ann_path, "w", encoding="utf-8") as f:
#         for tid, label, start, end, span_text in spans:
#             f.write(f"{tid}\t{label} {start} {end}\t{span_text}\n")

#     count += 1
#     if count % 100 == 0:
#         print(f"✅ Processed {count} CADEC files")

# print(f"\n🎉 Finished generating {count} CADEC-format .ann files from BIO outputs.")

"""Step 3: Evaluate Model Output vs Ground Truth

We'll use F1-score based on exact match of entity spans and labels.
"""

import os
import re
from collections import defaultdict

# --- Step 1: Label Mappings ---
final_labels = {"ADR", "DRUG", "DISEASE", "SYMPTOM"}

# For ground truth and predicted labels
label_mapping = {
    "ADR": "ADR",
    "ADVERSE_EFFECT": "ADR",
    "SIGN_SYMPTOM": "ADR",
    "CLINICAL_EVENT": "ADR",
    "FINDING": "ADR",

    "DRUG": "DRUG",
    "MEDICATION": "DRUG",
    "DRUG_NAME": "DRUG",
    "BRAND": "DRUG",

    "DISEASE": "DISEASE",
    "DISORDER": "DISEASE",
    "DISEASE_DISORDER": "DISEASE",

    "SYMPTOM": "SYMPTOM",  # This will now be a separate category
    "DETAILED_DESCRIPTION": "SYMPTOM",
}


# Skip all other labels
skip_labels = {
    "SEX", "TIME", "OCCUPATION", "AGE", "TEXTURE", "COLOR",
    "LAB_VALUE", "QUANTITATIVE_CONCEPT", "VALUE", "SUBJECT",
    "THERAPEUTIC_PROCEDURE", "DATE", "FREQUENCY", "DURATION",
    "DOSE", "SEVERITY", "HISTORY", "OUTCOME", "NONBIOLOGICAL_LOCATION",
    "OTHER", "OTHER_EVENT", "BODY_SITE", "ANATOMY",
    "BIOLOGICAL_STRUCTURE", "COREFERENCE", "AREA", "DISTANCE",
    "TEST_RESULT", "ADMINISTRATION", "ACTIVITY", "QUALITATIVE_CONCEPT"
}

def normalize_label(label):
    label = label.upper()
    if label in skip_labels:
        return None
    return label_mapping.get(label, None)  # only keep if mapped to ADR/DRUG/DISEASE/SYMPTOM

# --- Step 2: Load .ann files ---
def load_ann_files(folder):
    data = defaultdict(list)
    pattern = re.compile(r"^[A-Za-z]+\.\d+\.ann$")
    for file in os.listdir(folder):
        if not pattern.match(file):
            continue
        with open(os.path.join(folder, file), "r", encoding="utf-8") as f:
            for line in f:
                if not line.strip().startswith("T"):
                    continue
                parts = line.strip().split("\t")
                if len(parts) != 3:
                    continue
                try:
                    entity_id, entity_info, text = parts
                    raw_label, start, end = entity_info.split()[0], int(entity_info.split()[1]), int(entity_info.split()[2])
                    label = normalize_label(raw_label)
                    if label is None:
                        continue
                    data[file.replace(".ann", ".txt")].append({
                        "start": start,
                        "end": end,
                        "label": label,
                        "text": text.lower()
                    })
                except:
                    continue
    return data

# --- Step 3: Matching ---
def spans_overlap(pred, gold):
    return not (pred['end'] <= gold['start'] or pred['start'] >= gold['end'])

def labels_match(label1, label2):
    return label1 == label2

def is_match(pred, gold):
    return spans_overlap(pred, gold) and labels_match(pred['label'], gold['label'])

# --- Step 4: Evaluation ---
def evaluate(predictions, ground_truth):
    tp, fp, fn = 0, 0, 0

    for file in ground_truth:
        gold_ents = ground_truth[file]
        pred_ents = predictions.get(file, [])

        matched = [False] * len(gold_ents)

        for pred in pred_ents:
            found = False
            for i, gold in enumerate(gold_ents):
                if not matched[i] and is_match(pred, gold):
                    matched[i] = True
                    found = True
                    break
            if found:
                tp += 1
            else:
                fp += 1

        fn += matched.count(False)

    precision = tp / (tp + fp + 1e-10)
    recall = tp / (tp + fn + 1e-10)
    f1 = 2 * precision * recall / (precision + recall + 1e-10)

    print("\n=== CADEC Entity Evaluation ===")
    print(f"✅ True Positives: {tp}")
    print(f"❌ False Positives: {fp}")
    print(f"❌ False Negatives: {fn}")
    print(f"\n🎯 Precision: {precision:.4f}")
    print(f"🎯 Recall:    {recall:.4f}")
    print(f"🎯 F1 Score:  {f1:.4f}")

    return precision, recall, f1

# --- Step 5: Run Evaluation ---
gt_dir = "/content/CADECdataset/cadec/original"
pred_dir = "/content/output_cadec"

ground_truth = load_ann_files(gt_dir)
predictions = load_ann_files(pred_dir)

evaluate(predictions, ground_truth)

"""Misclassified Span Visualizer

Compares predicted vs. ground truth entities based on span overlap.
"""

from collections import Counter
import os
import re

# --- Helper: Check span overlap ---
def spans_overlap(e1, e2):
    return not (e1['end'] <= e2['start'] or e1['start'] >= e2['end'])

# --- Misclassified Span Collector ---
def get_top_misclassifications(predictions, ground_truth, top_n=10):
    misclassified = []

    for file in ground_truth:
        gt_ents = ground_truth[file]
        pred_ents = predictions.get(file, [])

        for pred in pred_ents:
            for gold in gt_ents:
                if spans_overlap(pred, gold):
                    if pred['label'] != gold['label']:
                        misclassified.append((
                            gold['label'],
                            pred['label'],
                            gold['text']
                        ))
                    break  # Only check against the first overlapping GT

    # Count most common mistakes
    counter = Counter((gt_label, pred_label) for gt_label, pred_label, _ in misclassified)
    print(f"\n🔍 Top {top_n} Misclassified Label Pairs:")
    for (gt, pred), count in counter.most_common(top_n):
        print(f"  - Ground Truth: {gt:10} → Predicted: {pred:10} | Count: {count}")

    # Optionally: Print examples
    print("\n📌 Sample Misclassified Spans:")
    seen = set()
    for gt, pred, text in misclassified:
        key = (gt, pred)
        if key not in seen:
            print(f"  - GT: {gt:10} | Pred: {pred:10} | Span: '{text}'")
            seen.add(key)
        if len(seen) >= top_n:
            break

get_top_misclassifications(predictions, ground_truth, top_n=10)

"""Print Unmatched Labels"""

all_labels = set()
for preds in predictions.values():
    all_labels.update(p['label'] for p in preds)
for trues in ground_truth.values():
    all_labels.update(e['label'] for e in trues)

print("\n🔍 All labels encountered:", sorted(all_labels))

from collections import Counter
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt

# -- Reuse your label_equivalents --
def labels_match(pred_label, gold_label):
    pred_set = label_mapping.get(pred_label.upper(), {pred_label.upper()})
    return gold_label.upper() in pred_set

# -- Span overlap logic (reused) --
def spans_overlap(pred, gold):
    return not (pred['end'] <= gold['start'] or pred['start'] >= gold['end'])

# -- Confusion Matrix Generator --
def build_confusion_matrix(predictions, ground_truth):
    label_pairs = []

    for file in ground_truth:
        gold_ents = ground_truth[file]
        pred_ents = predictions.get(file, [])

        matched = [False] * len(gold_ents)

        for pred in pred_ents:
            for i, gold in enumerate(gold_ents):
                if not matched[i] and spans_overlap(pred, gold):
                    label_pairs.append((pred["label"], gold["label"]))
                    if labels_match(pred["label"], gold["label"]):
                        matched[i] = True
                        break

    # Count (predicted, actual) label pairs
    counter = Counter(label_pairs)
    df_conf = pd.DataFrame([
        {"Predicted": k[0], "Ground Truth": k[1], "Count": v}
        for k, v in counter.items()
    ])

    print("\n📊 Confusion Matrix (Span Overlap Only):")
    print(df_conf.sort_values(by="Count", ascending=False).to_string(index=False))

    return df_conf


# Optional heatmap
def plot_confusion_heatmap(df_conf):
    pivot = df_conf.pivot(index='Ground Truth', columns='Predicted', values='Count').fillna(0)
    plt.figure(figsize=(12, 8))
    sns.heatmap(pivot, annot=True, fmt=".0f", cmap="YlGnBu", cbar=True)
    plt.title("NER Confusion Matrix (Predicted vs Ground Truth)")
    plt.ylabel("Ground Truth Label")
    plt.xlabel("Predicted Label")
    plt.tight_layout()
    plt.show()

# -- Call It --
conf_df = build_confusion_matrix(predictions, ground_truth)

# Optional visualization
plot_confusion_heatmap(conf_df)

""" Step 4: Evaluate for ADRs using meddra"""

#Ground truth - MEDDRA
test_file = "LIPITOR.417.ann"
data = defaultdict(list)
with open(os.path.join(meddra_path, test_file), "r", encoding="utf-8") as f:
    for line in f:
        if not line.strip().startswith("T"):
            continue
        parts = line.strip().split("\t")
        print(parts)

#Predicted - output_cadec
test_file = "LIPITOR.417.ann"
data = defaultdict(list)
with open(os.path.join("/content/output_cadec", test_file), "r", encoding="utf-8") as f:
    for line in f:
        if not line.strip().startswith("T"):
            continue
        parts = line.strip().split("\t")
        print(parts)

"""Issue: 10005886 is a Concept Unique Identifier (CUI) — not a label like DRUG or ADR.

Solution: Allowing your ground truth .ann files (with CUIs like 10005886) to be treated as "ADR".
"""

import os
import re
from collections import defaultdict

# --- Step 1: Label Mappings ---
final_labels = {"ADR"}  # Only ADR for evaluation

label_mapping = {
    "ADR": "ADR",
    "ADVERSE_EFFECT": "ADR",
    "SIGN_SYMPTOM": "ADR",
    "CLINICAL_EVENT": "ADR",
    "FINDING": "ADR",

    "DRUG": "DRUG",
    "MEDICATION": "DRUG",
    "DRUG_NAME": "DRUG",
    "BRAND": "DRUG",

    "DISEASE": "DISEASE",
    "DISORDER": "DISEASE",
    "DISEASE_DISORDER": "DISEASE",

    "SYMPTOM": "SYMPTOM",
    "DETAILED_DESCRIPTION": "SYMPTOM",
}

skip_labels = {
    "SEX", "TIME", "OCCUPATION", "AGE", "TEXTURE", "COLOR",
    "LAB_VALUE", "QUANTITATIVE_CONCEPT", "VALUE", "SUBJECT",
    "THERAPEUTIC_PROCEDURE", "DATE", "FREQUENCY", "DURATION",
    "DOSE", "SEVERITY", "HISTORY", "OUTCOME", "NONBIOLOGICAL_LOCATION",
    "OTHER", "OTHER_EVENT", "BODY_SITE", "ANATOMY",
    "BIOLOGICAL_STRUCTURE", "COREFERENCE", "AREA", "DISTANCE",
    "TEST_RESULT", "ADMINISTRATION", "ACTIVITY", "QUALITATIVE_CONCEPT"
}

def normalize_label(label):
    label = label.upper()
    if label in skip_labels:
        return None
    return label_mapping.get(label, None)

# --- Step 2: Load .ann files ---
def load_ann_files(folder):
    data = defaultdict(list)
    pattern = re.compile(r".*\.ann$")

    print(f"\n🔍 Looking in folder: {folder}")
    for file in os.listdir(folder):
        if not pattern.match(file):
            continue
        try:
            with open(os.path.join(folder, file), "r", encoding="utf-8") as f:
                found_valid_entity = False
                for line in f:
                    if not line.strip().startswith("T"):
                        continue
                    parts = line.strip().split("\t")
                    if len(parts) != 3:
                        continue

                    entity_id, entity_info, text = parts
                    parts_info = entity_info.split()
                    raw_label = parts_info[0]
                    start = int(parts_info[1])
                    end = int(parts_info[2])

                    # Patch: handle CUIs (numbers only) as ADR
                    if raw_label.isdigit():
                        label = "ADR"
                    else:
                        label = normalize_label(raw_label)
                        if label is None:
                            continue

                    found_valid_entity = True
                    data[file.replace(".ann", ".txt")].append({
                        "start": start,
                        "end": end,
                        "label": label,
                        "text": text.lower()
                    })

                # Even if no valid entities, still add empty list
                if not found_valid_entity:
                    data[file.replace(".ann", ".txt")] = []

        except Exception as e:
            print(f"❌ Error reading {file}: {e}")
            continue

        print(f"✅ Loaded: {file}")
    return data

# --- Step 3: Matching ---
def spans_overlap(pred, gold):
    return not (pred['end'] <= gold['start'] or pred['start'] >= gold['end'])

def labels_match(label1, label2):
    return label1 == label2

def is_match(pred, gold):
    return spans_overlap(pred, gold) and labels_match(pred['label'], gold['label'])

# --- Step 4: Evaluation ---
def evaluate(predictions, ground_truth):
    tp, fp, fn = 0, 0, 0

    for file in ground_truth:
        gold_ents = ground_truth[file]
        pred_ents = predictions.get(file, [])

        matched = [False] * len(gold_ents)

        for pred in pred_ents:
            found = False
            for i, gold in enumerate(gold_ents):
                if not matched[i] and is_match(pred, gold):
                    matched[i] = True
                    found = True
                    break
            if found:
                tp += 1
            else:
                fp += 1

        fn += matched.count(False)

    precision = tp / (tp + fp + 1e-10)
    recall = tp / (tp + fn + 1e-10)
    f1 = 2 * precision * recall / (precision + recall + 1e-10)

    print("\n=== CADEC ADR Evaluation ===")
    print(f"✅ True Positives: {tp}")
    print(f"❌ False Positives: {fp}")
    print(f"❌ False Negatives: {fn}")
    print(f"\n🎯 Precision: {precision:.4f}")
    print(f"🎯 Recall:    {recall:.4f}")
    print(f"🎯 F1 Score:  {f1:.4f}")

    return precision, recall, f1

# --- Step 5: Load and Filter ADR Only ---
def filter_adr_only(data):
    filtered = {}
    for file, ents in data.items():
        adr_ents = [ent for ent in ents if ent['label'] == "ADR"]
        filtered[file] = adr_ents  # Keep even if empty
    return filtered

# --- Step 6: Post Processing - Cleaning ------
import string

vague_terms = {
    "bad", "issue", "problem", "hurt", "feel", "worse", "felt", "symptom", "effect"
}

stopwords = {
    "a", "an", "the", "it", "i", "he", "she", "they", "we", "is", "are", "was", "to", "of", "in"
}

def clean_predictions(predictions, min_len=3):
    cleaned = {}
    for file, ents in predictions.items():
        seen = set()
        ents_sorted = sorted(ents, key=lambda x: (x['start'], -x['end']))  # Longest-first
        filtered_ents = []

        for ent in ents_sorted:
            span = (ent['start'], ent['end'])
            text = ent['text'].strip(string.punctuation).lower()

            if len(text) < min_len:
                continue
            if text in vague_terms or text in stopwords:
                continue
            if any(s[0] <= span[0] and s[1] >= span[1] for s in seen):
                continue

            seen.add(span)
            filtered_ents.append(ent)

        cleaned[file] = filtered_ents
    return cleaned

# --- Step 7: Run Everything ---
meddra_path = "/content/CADECdataset/cadec/meddra"
pred_path = "/content/output_cadec"

ground_truth_all = load_ann_files(meddra_path)
predictions_all = load_ann_files(pred_path)

# ✅ Step 1: Filter ADR from predictions only
predictions_adr = filter_adr_only(predictions_all)

# ✅ Step 2: Clean noisy/overlapping predictions
predictions_adr = clean_predictions(predictions_adr)

# 📊 Summary
print(f"\n📄 Loaded ground truth files: {len(ground_truth_all)}")
print(f"📄 Loaded prediction ADR files (after cleaning): {len(predictions_adr)}")

# ✅ Evaluate
evaluate(predictions_adr, ground_truth_all)

"""Step 5: Evaluate on 50 Random Posts"""

import os
import re
import random
from collections import defaultdict

# --- Step 1: Label Mappings ---
final_labels = {"ADR", "DRUG", "DISEASE", "SYMPTOM"}

# For ground truth and predicted labels
label_mapping = {
    "ADR": "ADR",
    "ADVERSE_EFFECT": "ADR",
    "SIGN_SYMPTOM": "ADR",
    "CLINICAL_EVENT": "ADR",
    "FINDING": "ADR",

    "DRUG": "DRUG",
    "MEDICATION": "DRUG",
    "DRUG_NAME": "DRUG",
    "BRAND": "DRUG",

    "DISEASE": "DISEASE",
    "DISORDER": "DISEASE",
    "DISEASE_DISORDER": "DISEASE",

    "SYMPTOM": "SYMPTOM",  # This will now be a separate category
    "DETAILED_DESCRIPTION": "SYMPTOM",
}


# Skip all other labels
skip_labels = {
    "SEX", "TIME", "OCCUPATION", "AGE", "TEXTURE", "COLOR",
    "LAB_VALUE", "QUANTITATIVE_CONCEPT", "VALUE", "SUBJECT",
    "THERAPEUTIC_PROCEDURE", "DATE", "FREQUENCY", "DURATION",
    "DOSE", "SEVERITY", "HISTORY", "OUTCOME", "NONBIOLOGICAL_LOCATION",
    "OTHER", "OTHER_EVENT", "BODY_SITE", "ANATOMY",
    "BIOLOGICAL_STRUCTURE", "COREFERENCE", "AREA", "DISTANCE",
    "TEST_RESULT", "ADMINISTRATION", "ACTIVITY", "QUALITATIVE_CONCEPT"
}

def normalize_label(label):
    label = label.upper()
    if label in skip_labels:
        return None
    return label_mapping.get(label, None)  # only keep if mapped to ADR/DRUG/DISEASE/SYMPTOM

# --- Step 2: Load .ann files ---
def load_ann_files(folder):
    data = defaultdict(list)
    pattern = re.compile(r"^[A-Za-z]+\.\d+\.ann$")
    for file in os.listdir(folder):
        if not pattern.match(file):
            continue
        with open(os.path.join(folder, file), "r", encoding="utf-8") as f:
            for line in f:
                if not line.strip().startswith("T"):
                    continue
                parts = line.strip().split("\t")
                if len(parts) != 3:
                    continue
                try:
                    entity_id, entity_info, text = parts
                    raw_label, start, end = entity_info.split()[0], int(entity_info.split()[1]), int(entity_info.split()[2])
                    label = normalize_label(raw_label)
                    if label is None:
                        continue
                    data[file.replace(".ann", ".txt")].append({
                        "start": start,
                        "end": end,
                        "label": label,
                        "text": text.lower()
                    })
                except:
                    continue
    return data

# --- Step 3: Matching ---
def spans_overlap(pred, gold):
    return not (pred['end'] <= gold['start'] or pred['start'] >= gold['end'])

def labels_match(label1, label2):
    return label1 == label2

def is_match(pred, gold):
    return spans_overlap(pred, gold) and labels_match(pred['label'], gold['label'])

# --- Step 4: Evaluation ---
def evaluate(predictions, ground_truth):
    tp, fp, fn = 0, 0, 0

    for file in ground_truth:
        gold_ents = ground_truth[file]
        pred_ents = predictions.get(file, [])

        matched = [False] * len(gold_ents)

        for pred in pred_ents:
            found = False
            for i, gold in enumerate(gold_ents):
                if not matched[i] and is_match(pred, gold):
                    matched[i] = True
                    found = True
                    break
            if found:
                tp += 1
            else:
                fp += 1

        fn += matched.count(False)

    precision = tp / (tp + fp + 1e-10)
    recall = tp / (tp + fn + 1e-10)
    f1 = 2 * precision * recall / (precision + recall + 1e-10)

    print("\n=== CADEC Entity Evaluation ===")
    print(f"✅ True Positives: {tp}")
    print(f"❌ False Positives: {fp}")
    print(f"❌ False Negatives: {fn}")
    print(f"\n🎯 Precision: {precision:.4f}")
    print(f"🎯 Recall:    {recall:.4f}")
    print(f"🎯 F1 Score:  {f1:.4f}")

    return precision, recall, f1


# --- Step 5: Random Sampling and Evaluation on 50 Forum Posts ---

# Path to forum post texts
text_path = "/content/CADECdataset/cadec/text"

# Get all .txt file names
all_txt_files = [f for f in os.listdir(text_path) if f.endswith(".txt")]

# Select 50 random files
random.seed(42)  # for reproducibility
selected_files = random.sample(all_txt_files, 50)

# Load full ground truth and predictions as before
gt_dir = "/content/CADECdataset/cadec/original"
pred_dir = "/content/output_cadec"

ground_truth_all = load_ann_files(gt_dir)
predictions_all = load_ann_files(pred_dir)

# Filter only selected files
ground_truth = {k: v for k, v in ground_truth_all.items() if k in selected_files}
predictions = {k: v for k, v in predictions_all.items() if k in selected_files}

# Evaluate
print(f"Evaluating on {len(selected_files)} randomly selected posts:")
evaluate(predictions, ground_truth)

"""# Step 6: Combine original + sct, map ADRs using string similarity and embedding

Part 1 -

1. Parses both original/ and sct/ .ann files

2. Matches each ADR text with its SNOMED CT term (based on exact or best fuzzy match for now)

3. Returns a list of dictionaries in the desired format:

{

  "code": "246636008",

  "term": "Blurred vision - hazy",

  "label": "ADR",

  "text": "little blurred vision"
  
}
"""

# !pip install "fuzzywuzzy[speedup]"
!pip install rapidfuzz

import os
from rapidfuzz import fuzz  # or fuzzywuzzy if you prefer

def parse_original_ann(filepath):
    adrs = []

    with open(filepath, 'r', encoding='utf-8') as f:
        lines = f.readlines()

    for line in lines:
        if line.startswith("T") and "\tADR " in line:
            parts = line.strip().split('\t')
            if len(parts) != 3:
                continue
            _, tag_info, text = parts
            label = tag_info.split()[0]
            adrs.append({
                "text": text.strip(),
                "label": label
            })
    return adrs


def parse_sct_ann(filepath):
    sct_mapping = []

    pattern = r'^TT\d+\t(\d+)\s*\|\s*(.*?)\s*\|\s*\d+\s+\d+\t(.+)'

    with open(filepath, 'r', encoding='utf-8') as f:
        for line in f:
            line = line.strip()
            if not line.startswith("TT"):
                continue

            match = re.match(pattern, line)
            if match:
                code = match.group(1)
                term = match.group(2)
                text = match.group(3)

                sct_mapping.append({
                    "code": code.strip(),
                    "term": term.strip(),
                    "text": text.strip()
                })
            else:
                print("❌ Skipping line (no match):", repr(line))

    return sct_mapping



def build_adr_data_structure(filename, original_dir, sct_dir, fuzzy_threshold=90):
    original_path = os.path.join(original_dir, filename)
    sct_path = os.path.join(sct_dir, filename)

    adrs = parse_original_ann(original_path)
    scts = parse_sct_ann(sct_path)

    final_results = []

    for adr in adrs:
        adr_text = adr["text"].lower()
        best_match = None
        best_score = -1

        for sct in scts:
            sct_text = sct["text"].lower()
            if adr_text == sct_text:
                best_match = sct
                break
            else:
                score = fuzz.ratio(adr_text, sct_text)
                if score > best_score and score >= fuzzy_threshold:
                    best_score = score
                    best_match = sct

        if best_match:
            final_results.append({
                "code": best_match["code"],
                "term": best_match["term"],
                "label": adr["label"],
                "text": adr["text"]
            })

    return final_results

results = build_adr_data_structure("ARTHROTEC.1.ann", "/content/CADECdataset/cadec/original", "/content/CADECdataset/cadec/sct")

for r in results:
    print(r)

import os
import json
from tqdm import tqdm  # for progress bar

def process_all_files(original_dir, sct_dir, output_path="normalized_adr_results.json"):
    all_results = []
    filenames = [f for f in os.listdir(original_dir) if f.endswith(".ann")]

    for fname in tqdm(filenames, desc="Processing Files"):
        try:
            result = build_adr_data_structure(fname, original_dir, sct_dir)
            all_results.extend(result)
        except Exception as e:
            print(f"[ERROR] Failed on {fname}: {e}")

    # Save to JSON
    with open(output_path, "w", encoding="utf-8") as f:
        json.dump(all_results, f, indent=2)

    print(f"\n✅ Normalized ADR data saved to: {output_path}")
    print(f"🔢 Total normalized entries: {len(all_results)}")
    return all_results

results = process_all_files(
    original_dir="/content/CADECdataset/cadec/original",
    sct_dir="/content/CADECdataset/cadec/sct",
    output_path="normalized_adr_results.json"
)

from google.colab import files
files.download('/content/normalized_adr_results.json')

from google.colab import files
files.download('/content/entities_by_file.json')

from google.colab import files
files.download('/content/fuzzy_adr_matches.json')

import shutil
from google.colab import files

# Step 1: Zip the folder
shutil.make_archive('/content/output_bio', 'zip', '/content/output_bio')

# Step 2: Download the zipped folder
files.download('/content/output_bio.zip')

import shutil
from google.colab import files

# Step 1: Zip the folder
shutil.make_archive('/content/output_cadec', 'zip', '/content/output_cadec')

# Step 2: Download the zipped folder
files.download('/content/output_cadec.zip')

"""Part 2A: Approximate String Matching using Levenshtein distance (i.e., fuzzy match)!"""

#Function to Match via Fuzzy String Similarity

from rapidfuzz import fuzz  # much faster and better than fuzzywuzzy

def match_fuzzy(adr_text, sct_terms, threshold=85):
    """
    Match ADR mention to the best SNOMED term using fuzzy matching.
    Returns: dict with best code, term, score
    """
    best_match = None
    best_score = -1

    adr_text = adr_text.lower()

    for sct in sct_terms:
        term = sct["term"].lower()
        score = fuzz.ratio(adr_text, term)
        if score > best_score and score >= threshold:
            best_score = score
            best_match = {
                "code": sct["code"],
                "term": sct["term"],
                "score": score
            }

    return best_match


#Updated build_adr_data_structure_fuzzy() Using This
def build_adr_data_structure_fuzzy(filename, original_dir, sct_dir, threshold=85):
    original_path = os.path.join(original_dir, filename)
    sct_path = os.path.join(sct_dir, filename)

    adrs = parse_original_ann(original_path)
    scts = parse_sct_ann(sct_path)

    results = []

    for adr in adrs:
        adr_text = adr["text"]
        match = match_fuzzy(adr_text, scts, threshold)

        if match:
            results.append({
                "adr_text": adr_text,
                "match_fuzzy": {
                    "code": match["code"],
                    "term": match["term"],
                    "score": match["score"]
                },
                "original_label": adr["label"]
            })

    return results

scts = parse_sct_ann("/content/CADECdataset/cadec/sct/ARTHROTEC.1.ann")
print("Total SNOMED CT terms extracted:", len(scts))
for entry in scts:
    print(entry)

results = build_adr_data_structure_fuzzy(
    "ARTHROTEC.1.ann",
    original_dir="/content/CADECdataset/cadec/original",
    sct_dir="/content/CADECdataset/cadec/sct",
    threshold=70
)

for r in results:
    print(r)

import os
import json
from tqdm import tqdm

def process_all_files_fuzzy(original_dir, sct_dir, threshold=85, output_path="fuzzy_adr_matches.json"):
    all_results = []
    filenames = [f for f in os.listdir(original_dir) if f.endswith(".ann")]

    for fname in tqdm(filenames, desc="🔍 Matching ADRs via Fuzzy"):
        try:
            file_results = build_adr_data_structure_fuzzy(fname, original_dir, sct_dir, threshold)
            all_results.extend(file_results)
        except Exception as e:
            print(f"[ERROR] in {fname}: {e}")

    # Save as JSON
    with open(output_path, "w", encoding="utf-8") as f:
        json.dump(all_results, f, indent=2)

    print(f"\n✅ Saved {len(all_results)} fuzzy-matched ADR entries to: {output_path}")
    return all_results

results_fuzzy = process_all_files_fuzzy(
    original_dir="/content/CADECdataset/cadec/original",
    sct_dir="/content/CADECdataset/cadec/sct",
    threshold=75,  # or 80 if you want stricter matches
    output_path="fuzzy_adr_matches.json"
)

from google.colab import files
files.download('/content/normalized_adr_results.json')

"""Part 2B: Embedding-Based Semantic Matching"""

!pip install -U sentence-transformers

from sentence_transformers import SentenceTransformer, util

model = SentenceTransformer('all-MiniLM-L6-v2')
model

#define matching function

def match_embedding(adr_text, sct_terms):
    """
    Match ADR span to best SNOMED term using sentence embedding similarity.
    Returns: dict with best code, term, score
    """
    adr_emb = model.encode(adr_text, convert_to_tensor=True)

    # Create a list of SNOMED terms
    sct_texts = [term['term'] for term in sct_terms]
    sct_embs = model.encode(sct_texts, convert_to_tensor=True)

    # Compute cosine similarity
    cos_scores = util.cos_sim(adr_emb, sct_embs)[0]

    # Find best match
    best_idx = cos_scores.argmax().item()
    best_score = cos_scores[best_idx].item()

    return {
        "code": sct_terms[best_idx]["code"],
        "term": sct_terms[best_idx]["term"],
        "score": round(best_score, 4)
    }

#Wrap in Data Builder (per file)
def build_adr_data_structure_embed(filename, original_dir, sct_vocab):
    adrs = parse_original_ann(os.path.join(original_dir, filename))
    results = []

    for adr in adrs:
        adr_text = adr["text"]
        match = match_embedding(adr_text, sct_vocab)

        if match:
            results.append({
                "adr_text": adr_text,
                "match_embedding": {
                    "code": match["code"],
                    "term": match["term"],
                    "score": match["score"]
                },
                "original_label": adr["label"]
            })

    return results

def process_all_files_embed(original_dir, sct_vocab, output_path="embedding_adr_matches.json"):
    from tqdm import tqdm
    all_results = []
    filenames = [f for f in os.listdir(original_dir) if f.endswith(".ann")]

    for fname in tqdm(filenames, desc="🔍 Embedding Matching"):
        try:
            file_results = build_adr_data_structure_embed(fname, original_dir, sct_vocab)
            all_results.extend(file_results)
        except Exception as e:
            print(f"[ERROR] in {fname}: {e}")

    # Save to JSON
    with open(output_path, "w", encoding="utf-8") as f:
        json.dump(all_results, f, indent=2)

    print(f"✅ Embedding-based results saved to: {output_path}")
    print(f"🔢 Total matched ADRs: {len(all_results)}")
    return all_results

import os

def build_global_sct_vocabulary(sct_dir):
    """
    Extract all unique SNOMED CT terms and codes from all .ann files in the /sct/ directory.
    """
    seen = set()
    sct_vocab = []

    for fname in os.listdir(sct_dir):
        if not fname.endswith(".ann"):
            continue

        try:
            with open(os.path.join(sct_dir, fname), "r", encoding="utf-8", errors="ignore") as f:
                for line in f:
                    if "CONCEPT_LESS" in line:
                        continue

                    parts = line.strip().split("\t")
                    if len(parts) < 2:
                        continue

                    try:
                        tag_id, tag_data = parts[0], parts[1]
                        code = tag_data.split("|")[0].strip()
                        term = tag_data.split("|")[1].strip()
                        key = (code, term)
                        if key not in seen:
                            sct_vocab.append({"code": code, "term": term})
                            seen.add(key)
                    except:
                        continue
        except Exception as e:
            print(f"[ERROR] in file {fname}: {e}")

    print(f"✅ Global SNOMED CT vocabulary size: {len(sct_vocab)} terms")
    return sct_vocab

def parse_original_ann(filepath):
    """
    Extract ADR-labeled entities from a CADEC .ann file (original/ directory).
    Returns a list of dicts with keys: 'text' and 'label'
    """
    adrs = []

    try:
        with open(filepath, "r", encoding="utf-8") as f:
            for line in f:
                if line.startswith("T"):  # Only extract entity lines
                    parts = line.strip().split("\t")
                    if len(parts) == 3:
                        tag_id, tag_info, text = parts
                        label = tag_info.split()[0]
                        if label == "ADR":
                            adrs.append({
                                "text": text,
                                "label": label
                            })
    except Exception as e:
        print(f"[ERROR] parsing original file {filepath}: {e}")

    return adrs

import json
sct_vocab = build_global_sct_vocabulary("/content/CADECdataset/cadec/sct")

results_embed = process_all_files_embed(
    original_dir="/content/CADECdataset/cadec/original",
    sct_vocab=sct_vocab,
    output_path="embedding_adr_matches.json"
)

minutes, seconds = divmod(elapsed_time, 60)
print(f"⏱️ Time taken: {int(minutes)} min {int(seconds)} sec")

from google.colab import files
files.download('/content/embedding_adr_matches.json')

"""Part 3: Evaluation & Comparison."""

import json

with open("/content/fuzzy_adr_matches.json") as f1:
    fuzzy_matches = json.load(f1)

with open("/content/embedding_adr_matches.json") as f2:
    embed_matches = json.load(f2)

#Mapping created to compare both files
from collections import defaultdict

# Map from ADR text → fuzzy + embedding
comparison_dict = defaultdict(dict)

for entry in fuzzy_matches:
    key = entry["adr_text"].strip().lower()
    comparison_dict[key]["fuzzy"] = entry["match_fuzzy"]

for entry in embed_matches:
    key = entry["adr_text"].strip().lower()
    comparison_dict[key]["embed"] = entry["match_embedding"]

#Analyze the Differences
same_code = 0
different_code = 0
only_fuzzy = 0
only_embed = 0
both_present = 0

diff_examples = []

for adr_text, matches in comparison_dict.items():
    fuzzy = matches.get("fuzzy")
    embed = matches.get("embed")

    if fuzzy and embed:
        both_present += 1
        if fuzzy["code"] == embed["code"]:
            same_code += 1
        else:
            different_code += 1
            diff_examples.append({
                "adr_text": adr_text,
                "fuzzy_code": fuzzy["code"],
                "fuzzy_term": fuzzy["term"],
                "embed_code": embed["code"],
                "embed_term": embed["term"],
                "fuzzy_score": fuzzy["score"],
                "embed_score": embed["score"]
            })
    elif fuzzy:
        only_fuzzy += 1
    elif embed:
        only_embed += 1

#Summary Report
print("📊 Match Comparison Summary")
print(f"✅ Total ADRs with both matches       : {both_present}")
print(f"✅ Matches with same SNOMED code     : {same_code}")
print(f"❌ Matches with different SNOMED code: {different_code}")
print(f"🔹 Only in fuzzy results             : {only_fuzzy}")
print(f"🔹 Only in embedding results         : {only_embed}")


print("\n🔍 Examples where codes differ:")
for e in diff_examples[:5]:
    print(f"\nADR: {e['adr_text']}")
    print(f" - Fuzzy → {e['fuzzy_term']} ({e['fuzzy_code']}) | Score: {e['fuzzy_score']}")
    print(f" - Embed → {e['embed_term']} ({e['embed_code']}) | Score: {e['embed_score']}")

import matplotlib.pyplot as plt
from matplotlib_venn import venn2

# === Raw numbers from your summary ===
both = 511
same = 455
diff = 56
only_fuzzy = 0
only_embed = 2889

# -------------------------------
# 1. Venn Diagram
plt.figure(figsize=(6,6))
venn2(subsets = (only_fuzzy, only_embed, both),
      set_labels = ('Fuzzy Matches', 'Embedding Matches'),
      set_colors=('skyblue', 'lightgreen'),
      alpha=0.7)
plt.title("🧠 Fuzzy vs Embedding ADR Matches")
plt.show()

# -------------------------------
# 2. Bar Chart
plt.figure(figsize=(6,4))
plt.bar(["Same Code", "Different Code"], [same, diff], color=["green", "orange"])
plt.ylabel("Count")
plt.title("✅ Match Agreement Between Methods")
plt.show()

# -------------------------------
# 3. Pie Chart
labels = ["Same Code", "Different Code", "Embedding Only"]
sizes = [same, diff, only_embed]
colors = ["#8fd9a8", "#f9cb9c", "#c9daf8"]

plt.figure(figsize=(5.5,5.5))
plt.pie(sizes, labels=labels, autopct='%1.1f%%', startangle=140, colors=colors)
plt.title("📊 Distribution of Match Types")
plt.axis('equal')  # Equal aspect ratio ensures pie is circular.
plt.show()

